---
layout: post
title: What AI can't do: naming thoughts
date: 2021-09-25 09:07
excerpt_separator: <!--more-->
bannerimg: /img/posts/dictionary.jpg
photographer: Tamara Menzi
photographerurl: https://unsplash.com/@itstamaramenzi
tags: ai
---

Shannon Vallor's piece about [the thoughts the civilized keep](https://www.noemamag.com/the-thoughts-the-civilized-keep/) is a very good critique of the modern hype surrounding AI, and it eviscerates GPT-3 very nicely. Her key point is that machines allow us to do what Alfred Whitehead suggested over one hundred years ago - "\[extend\] the number of important operations which we can perform without thinking about them." GPT-3 and its fellow traveler AI algorithms are no different.

My vocabulary for discussing this idea is slightly different from Vallor's, but with very similar intent and meaning. My working hypothesis about the limits of AI is as follows: that it cannot, and never will be able to, properly name a thought. This hypothesis will get something of a trial run, incidentally, in The Game - which is the short story I'm working on these days.

The problem of good naming is infamously considered one of the hardest problems in computer science. It is also not very well-defined! One might say that it's the problem of picking a word or short phrase which efficiently summarizes a larger body of thought. For example, "hyper text transfer protocol" is a name for a very large body of specifications about how web servers and browsers (among other clients) communicate with each other.

It's also not very easy to discern what makes a name "good". Is HTTP actually a good name for the protocol it refers to? That is debatable, and there is no agreed-upon metric for rendering judgement. In a less grandiose context we might consider a code base managed by a team or two, and pick a function out of that code base. Is the function well-named? We could maybe endeavor to measure the property of well-named-ness - for example, we could look at how often that function name is changed, or how many defects arise from that function. That would be a start, although Goodhart's Law means we could never get a fully satisfactory answer!

Ultimately I think my working hypothesis amounts to something like tautology - and [tautological arguments are about the best we've got](https://shaisachs.com/2020/07/27/argument-from-tautology.html) in this area. Could you design an AI algorithm which, given a corpus of text, picks a title for that text? You certainly could, and probably you could design such an algorithm and get some pretty impressive results - judged subjectively, and in small, cherry-picked batches. 

Does that mean that we've designed an intelligent algorithm? I think not, and Vallor's piece points to the reason why. It's because AI would do a good job providing names for textual corpuses that are reasonably similar to pre-existing corpuses. If you fed in the the first few chapters of a Charles Dickens novel, you may well get back a title like "Great Expectations," and wouldn't that be fine. But if you fed in an entirely new piece of writing - let's pretend we roll back the clock to the mid-80s, and we use a magic time machine to feed this hypothetical AI algorithm something like the first few paragraphs of Beloved - would you indeed get back a title as elegant as Toni Morrison's?